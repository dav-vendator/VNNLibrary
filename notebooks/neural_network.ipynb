{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Implementation of NN from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.typing import ArrayLike\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import Callable, Tuple,Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A simple class that represents NN\n",
    "from typing import Any\n",
    "\n",
    "class VNNModule(ABC):\n",
    "    \"\"\"\"\"\"\n",
    "    def __init__(self, name):\n",
    "        super().__init__()\n",
    "        self.module_name = name #for debugging purpose\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return  f'{self.__class__.__name__}--{self.module_name}' \n",
    "    \n",
    "    def __call__(self, x: Any) -> Any:\n",
    "        return self.forward(x)\n",
    "    \n",
    "    @abstractmethod\n",
    "    def summary(self) -> Dict[str, int]:\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def forward(self, x: Any) -> Any:\n",
    "        \"\"\"Forward pass to process input x.\"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def backward(self, from_front: Any) -> Any:\n",
    "        \"\"\"Backward pass for gradient calculation.\"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VLinearLayer(VNNModule):\n",
    "    def __init__(self, input_size:int, output_size: int, weight_initialize: np.ndarray = None, bias_initialize: np.ndarray = None):\n",
    "        super().__init__(f'VLinearLayer mapping {input_size} -> {output_size}')\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        #TODO: Replace random initialization with standard techniques\n",
    "        self.WeightMatrix = np.random.rand(self.input_size, self.output_size) if weight_initialize is None else weight_initialize\n",
    "        self.bias = np.random.rand(self.output_size) if bias_initialize is None else bias_initialize \n",
    "        #sanity check \n",
    "        if self.WeightMatrix.shape != (input_size, output_size):\n",
    "            raise ValueError('Input and output sizes did not matched with the weight matrix size.')\n",
    "        if self.bias.shape != (output_size,):\n",
    "            raise ValueError('Output size did not matched with the bias vector size.')\n",
    "        #for computation of gradients\n",
    "        self.forward_acc = None\n",
    "        self.backward_acc = None\n",
    "\n",
    "    def forward(self, x: np.ndarray) -> np.ndarray:\n",
    "        #forward pass is simple to implement\n",
    "        #Linear layer has equation == f(x) = W.x + b\n",
    "        if x.shape[0] != self.input_size:\n",
    "            raise ValueError(f\"Input size {x.shape[0]} does not match expected input size {self.input_size}.\")\n",
    "        out = np.dot(x, self.WeightMatrix)\n",
    "        out += self.bias\n",
    "        self.forward_acc  = out\n",
    "        return out\n",
    "\n",
    "    def clear_accumulations(self) -> None:\n",
    "        self.forward_acc = None\n",
    "        self.backward_acc = None\n",
    "\n",
    "    def backward(self, from_front: np.ndarray) -> Tuple[np.ndarray]:\n",
    "        #compute gradient of weights and biases and multiply them with from front\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VConvLayer(VNNModule):\n",
    "    # Implement convolutional layer here\n",
    "    pass\n",
    "\n",
    "class VPoolingLayer(VNNModule):\n",
    "    # Implement pooling layer here\n",
    "    pass\n",
    "\n",
    "class VDropOutLayer(VNNModule):\n",
    "    # Implement dropout layer here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VSigmoidLayer(VNNModule):\n",
    "    def __init__(self):\n",
    "        super().__init__(f'VSigmoid Layer')\n",
    "        self.sigmoid = np.vectorize(lambda x: 1.0/(1+np.exp(-x)))\n",
    "        self.forward_acc = None\n",
    "        self.backward_acc = None\n",
    "\n",
    "    def forward(self, x: np.ndarray) -> np.ndarray:\n",
    "            #forward pass \n",
    "            out = self.sigmoid(x)\n",
    "            self.forward_acc = out\n",
    "            return  out\n",
    "    \n",
    "    def clear_accumulations(self) -> None:\n",
    "            self.forward_acc = None\n",
    "            self.backward_acc = None\n",
    "    \n",
    "    def backward(self, from_front:np.ndarray) -> np.ndarray:\n",
    "        sigmoid_grad = self.forward_acc * (1 - self.forward_acc)\n",
    "        self.backward_acc = sigmoid_grad * from_front\n",
    "        return self.backward_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence wise execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VSequence(VNNModule):\n",
    "    def __init__(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_layer = VLinearLayer(10, 5)\n",
    "sigmoid_layer = VSigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9640014 , 0.86708246, 0.94438228, 0.96899222, 0.73785163])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid_layer(linear_layer(np.random.randn(10)))รท"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "q_ml2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
